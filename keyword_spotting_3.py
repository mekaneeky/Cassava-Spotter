# -*- coding: utf-8 -*-
"""Keyword_Spotting_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I9jZcMsBm32yC9V8GreXm3x2s8jKCyFi
"""

#!gcloud auth login

#!gcloud config set project malaria-detect

#!mkdir data

#!gsutil -m cp -R gs://nlp_keyword_bucket ./data/

#!clear

import os
from utils.processor_class import DataProcessor

## Some preparation code

processor = DataProcessor("data/nlp_keyword_bucket/train_1/", 
            "data/nlp_keyword_bucket/val_1/",
            "data/nlp_keyword_bucket/test_1/")
processor.convert_ogg2wav()

from utils.visualizers import *
from utils.img_loaders import *


###  Parameters ###
fft_size = 2048  # window size for the FFT
step_size = fft_size // 16  # distance to slide along the window (in time)
spec_thresh = 4  # threshold for spectrograms (lower filters out more noise)
lowcut = 500  # Hz # Low cut for our butter bandpass filter
highcut = 15000  # Hz # High cut for our butter bandpass filter
# For mels
n_mel_freq_components = 64  # number of mel frequency channels
shorten_factor = 10  # how much should we compress the x-axis (time)
start_freq = 300  # Hz # What frequency to start sampling our melS from
end_freq = 8000  # Hz # What frequency to stop sampling our melS from

#!ls

# Grab your wav and filter it
mywav = "data/nlp_keyword_bucket/train_1/amatooke/4db337b1ecbd4a67bbecbd503d74750a_63ef8eb9fa2c4145bd7feb4ab6a76a78.wav"
rate, data = wavfile.read(mywav)
data = butter_bandpass_filter(data, lowcut, highcut, rate, order=1)
# Only use a short clip for our demo
if np.shape(data)[0] / float(rate) > 10:
    data = data[0 : rate * 10]
print("Length in time (s): ", np.shape(data)[0] / float(rate))
# Play the audio
IPython.display.Audio(data=data, rate=rate)

wav_spectrogram = pretty_spectrogram(
    data.astype("float64"),
    fft_size=fft_size,
    step_size=step_size,
    log=True,
    thresh=spec_thresh,
)

fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 4))
cax = ax.matshow(
    np.transpose(wav_spectrogram),
    interpolation="nearest",
    aspect="auto",
    cmap=plt.cm.afmhot,
    origin="lower",
)
fig.colorbar(cax)
plt.title("Original Spectrogram")

# Generate the mel filters
mel_filter, mel_inversion_filter = create_mel_filter(
    fft_size=fft_size,
    n_freq_components=n_mel_freq_components,
    start_freq=start_freq,
    end_freq=end_freq,
)

fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 4))
ax[0].matshow(
    np.transpose(mel_filter), cmap=plt.cm.afmhot, interpolation="nearest", aspect="auto"
)
ax[0].set_title("mel Filter")
ax[1].matshow(
    mel_inversion_filter, cmap=plt.cm.afmhot, interpolation="nearest", aspect="auto"
)
ax[1].set_title("mel Inversion Filter")

mel_spec = make_mel(wav_spectrogram, mel_filter, shorten_factor=shorten_factor)

# plot the compressed spec


fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 4))
cax = ax.matshow(
    mel_spec.astype("float32"),
    interpolation="nearest",
    aspect="auto",
    cmap=plt.cm.afmhot,
    origin="lower",
)
plt.axis('off')
path_to_file = mywav.split('.')[0]
savename = path_to_file + '.png'
plt.savefig(savename)
#fig.colorbar(cax)
#plt.title("mel Spectrogram")
#########################################################################################################
# END OF PLOTTING BIT
######################################################################################################### 

#########################################################################################################
# BEGINNING OF GENERATING SPECTROGRAM IMAGES FOR WAV FILES
######################################################################################################### 

processor.generate_dir_spectograms()

#########################################################################################################
# END OF GENERATING SPECTROGRAM IMAGES FOR WAV FILES
######################################################################################################### 


#########################################################################################################
# BEGINNING OF GENERATING TRAIN VAL TEST SPLIT
# ADD ABILITY TO GENERATE FROM BIG MIXED FOLDER FOR K FOLD CROSS VALIDATION
# ADD K FOLD CROSS VALIDATION
#########################################################################################################

#from sklearn.model_selection import train_test_split
from utils.img_loaders import loadimgs

Xtrain, ytrain, word_dict_train = loadimgs(path='data/nlp_keyword_bucket/train_1/')
Xval, yval, word_dict_val = loadimgs(path='data/nlp_keyword_bucket/val_1/')
Xtest, ytest, word_dict_test = loadimgs(path='data/nlp_keyword_bucket/test_1/')


#########################################################################################################
# END OF GENERATING TRAIN VAL TEST SPLIT
#########################################################################################################

from utils.model_loaders import TeacherModelLoader
teacher_model_loader = TeacherModelLoader(Xtrain, Xval, Xtest,(32,100,3))
teacher_model_loader.get_model()

from keras.models import load_model
# If loading an existing model
#teacher_model_loader.model_to_use = load_model('gdrive/My Drive/best_siamese.h5')

#########################################################################################################
# BEGGINING OF SIAMESE TEACHER TRAINING
#########################################################################################################

teacher_model_loader.train_model()


#########################################################################################################
# END OF SIAMESE TEACHER TRAINING
#########################################################################################################

#########################################################################################################
# BEGGINING OF EVALUATING SIAMESE MODEL
#########################################################################################################

teacher_model_loader.evaluate_model()

#########################################################################################################
# END OF EVALUATING SIAMESE MODEL
#########################################################################################################

#########################################################################################################
# BEGGINING OF TESTING SIAMESE TEACHER ON CONTINOUS STREAM
#########################################################################################################

#S_DB.dtype
gen_of_cut_up_arr = big_bad_generator_for_one_shot_tasks_from_cut_ups(S_DB, Xtrain,None)
list_of_cut_up_arr_lists = generate_window_walks(S_DB)

print(6614912/sr/60)
list_of_cut_up_sounds_lists = generate_window_walks(S_DB)

total_count = 0
for list_arr in list_of_cut_up_arr_lists:
  total_count += len(list_arr)
print(total_count)


big_bad_generataar =  GeneratorClass(radio_show, S_DB, Xtrain, sr, total_count , word_dict_train)
bbg = big_bad_generataar.__iter__()

big_bad_gen = big_bad_generator_for_one_shot_tasks_from_cut_ups(S_DB, Xtrain, None)

big_bad_gen = big_bad_generator_for_one_shot_tasks_from_cut_ups(S_DB, Xtrain, None)

prediction_of_one_shot_baby = teacher_model_loader.model_to_use.predict_generator(bbg, 100, verbose=1)#total_count



#########################################################################################################
# END OF TESTING SIAMESE TEACHER ON CONTINOUS STREAM
#########################################################################################################

#########################################################################################################
# BEGGINING OF GENERATING STUDENT TRAINING PREDICTIONS
#########################################################################################################

preds_of_siamese, xtest_preds_of_siamese = teacher_model_loader.gen_student_preds()

#########################################################################################################
# END OF GENERATING STUDENT TRAINING PREDICTIONS
#########################################################################################################

from utils.model_loaders import StudentModelLoader

student_model_loader = StudentModelLoader(preds_of_siamese, xtest_preds_of_siamese, input_shape = (128,128,3) )
student_model_loader.get_model()


#########################################################################################################
# BEGGINING OF STUDENT DISTILLATION TRAINING
#########################################################################################################


student_model_loader.train_model()
#########################################################################################################
# END OF STUDENT DISTILLATION TRAINING
#########################################################################################################

#########################################################################################################
# BEGINNING OF STUDENT DISTILLATION TESTING
#########################################################################################################

from utils.generators import get_batch_test_distillation, find_maximum_distill_N_top_values

images, targets = get_batch_test_distillation(teacher_model_loader.Xtest)

predicted_targets = student_model_loader.model_to_use.predict(images, batch_size=32, verbose=1)

max_pred_vals = find_maximum_distill_N_top_values(Xtest, predicted_targets)

from sklearn.metrics import classification_report
# import json
CLASS_REPORT_SIAM = classification_report(max_pred_vals_siamese, max_pred_vals)

print(CLASS_REPORT_SIAM)

#########################################################################################################
# END OF STUDENT DISTILLATION TESTING
#########################################################################################################



